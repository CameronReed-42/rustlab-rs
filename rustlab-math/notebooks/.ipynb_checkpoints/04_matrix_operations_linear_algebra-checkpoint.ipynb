{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-title",
   "metadata": {},
   "source": [
    "# Matrix Operations and Linear Algebra Basics\n",
    "\n",
    "This notebook demonstrates advanced matrix operations using rustlab-math, including:\n",
    "- Matrix creation and manipulation\n",
    "- Basic linear algebra operations\n",
    "- Matrix decompositions\n",
    "- Solving linear systems\n",
    "\n",
    "**Prerequisites**: Basic understanding of linear algebra concepts\n",
    "\n",
    "## Setup\n",
    "\n",
    "**Important**: The setup cell below follows Rust notebook best practices:\n",
    "- Dependencies and imports are declared at the **top level** (outside braces) so they persist across all cells\n",
    "- Test code is wrapped in braces `{}` to avoid persistence issues with complex types\n",
    "- This pattern ensures compatibility with both rust-analyzer and evcxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RustLab Matrix Operations Demo\n",
      "Test matrix shape: 2x2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Setup Cell - dependencies and imports persist across all cells\n",
    ":dep rustlab-math = { path = \"..\" }\n",
    ":dep rustlab-linearalgebra = { path = \"../rustlab-linearalgebra\" }\n",
    "\n",
    "// Top-level imports - these persist across all cells!\n",
    "use rustlab_math::*;\n",
    "use rustlab_linearalgebra::*; // For decompositions\n",
    "\n",
    "// Test setup in braces (variables don't persist, but confirms setup works)\n",
    "{\n",
    "    let test_matrix = array64![[1.0, 2.0], [3.0, 4.0]];\n",
    "    println!(\"✅ RustLab Matrix Operations Demo\");\n",
    "    println!(\"Test matrix shape: {}x{}\", test_matrix.nrows(), test_matrix.ncols());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matrix-creation",
   "metadata": {},
   "source": [
    "## Matrix Creation and Basic Properties\n",
    "\n",
    "Let's start by creating matrices and exploring their basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "basic-matrices",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "   1.0    2.0    3.0 \n",
      "   4.0    5.0    6.0 \n",
      "   7.0    8.0    9.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Create different types of matrices\n",
    "let matrix_a = array64![\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]\n",
    "];\n",
    "\n",
    "let matrix_b = array64![\n",
    "    [9.0, 8.0, 7.0],\n",
    "    [6.0, 5.0, 4.0],\n",
    "    [3.0, 2.0, 1.0]\n",
    "];\n",
    "\n",
    "// Identity matrix with explicit type annotation\n",
    "let identity_matrix: ArrayF64 = eye(3);\n",
    "\n",
    "// Zero matrix with explicit naming\n",
    "let zero_matrix = ArrayF64::zeros(3, 3);\n",
    "\n",
    "// Create a sample matrix (instead of random)\n",
    "let sample_data = array64![\n",
    "    [0.1, 0.4, 0.7],\n",
    "    [0.2, 0.5, 0.8],\n",
    "    [0.3, 0.6, 0.9]\n",
    "];\n",
    "\n",
    "println!(\"Matrix A:\");\n",
    "for i in 0..matrix_a.nrows() {\n",
    "    for j in 0..matrix_a.ncols() {\n",
    "        print!(\"{:6.1} \", matrix_a.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "println!(\"\\nMatrix B:\");\n",
    "for i in 0..matrix_b.nrows() {\n",
    "    for j in 0..matrix_b.ncols() {\n",
    "        print!(\"{:6.1} \", matrix_b.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "println!(\"\\nIdentity matrix:\");\n",
    "for i in 0..identity_matrix.nrows() {\n",
    "    for j in 0..identity_matrix.ncols() {\n",
    "        print!(\"{:6.1} \", identity_matrix.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "println!(\"\\nMatrix dimensions: {} x {}\", matrix_a.nrows(), matrix_a.ncols());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matrix-arithmetic",
   "metadata": {},
   "source": [
    "## Matrix Arithmetic Operations\n",
    "\n",
    "RustLab supports all standard matrix arithmetic with natural mathematical notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arithmetic-ops",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix B:\n",
      "   9.0    8.0    7.0 \n",
      "   6.0    5.0    4.0 \n",
      "   3.0    2.0    1.0 \n",
      "\n",
      "Identity matrix:\n",
      "   1.0    0.0    0.0 \n",
      "   0.0    1.0    0.0 \n",
      "   0.0    0.0    1.0 \n",
      "\n",
      "Matrix dimensions: 3 x 3\n",
      "A + B:\n",
      "  10.0   10.0   10.0 \n",
      "  10.0   10.0   10.0 \n",
      "  10.0   10.0   10.0 \n",
      "\n",
      "A - B:\n",
      "  -8.0   -6.0   -4.0 \n",
      "  -2.0    0.0    2.0 \n",
      "   4.0    6.0    8.0 \n",
      "\n",
      "2 * A:\n",
      "   2.0    4.0    6.0 \n",
      "   8.0   10.0   12.0 \n",
      "  14.0   16.0   18.0 \n",
      "\n",
      "A ⊙ B (element-wise):\n",
      "   9.0   16.0   21.0 \n",
      "  24.0   25.0   24.0 \n",
      "  21.0   16.0    9.0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Matrix addition and subtraction\n",
    "let sum_result = &matrix_a + &matrix_b;\n",
    "let diff_result = &matrix_a - &matrix_b;\n",
    "\n",
    "println!(\"A + B:\");\n",
    "for i in 0..sum_result.nrows() {\n",
    "    for j in 0..sum_result.ncols() {\n",
    "        print!(\"{:6.1} \", sum_result.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "println!(\"\\nA - B:\");\n",
    "for i in 0..diff_result.nrows() {\n",
    "    for j in 0..diff_result.ncols() {\n",
    "        print!(\"{:6.1} \", diff_result.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Scalar multiplication\n",
    "let scaled_matrix = &matrix_a * 2.0;\n",
    "println!(\"\\n2 * A:\");\n",
    "for i in 0..scaled_matrix.nrows() {\n",
    "    for j in 0..scaled_matrix.ncols() {\n",
    "        print!(\"{:6.1} \", scaled_matrix.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Element-wise multiplication (Hadamard product)\n",
    "let hadamard_result = &matrix_a * &matrix_b;\n",
    "println!(\"\\nA ⊙ B (element-wise):\");\n",
    "for i in 0..hadamard_result.nrows() {\n",
    "    for j in 0..hadamard_result.ncols() {\n",
    "        print!(\"{:6.1} \", hadamard_result.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matrix-multiplication",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "The `^` operator provides natural mathematical notation for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matrix-mult",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A × B (matrix multiplication):\n",
      "  30.0   24.0   18.0 \n",
      "  84.0   69.0   54.0 \n",
      " 138.0  114.0   90.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Matrix multiplication using ^ operator\n",
    "let multiplication_result = &matrix_a ^ &matrix_b;\n",
    "println!(\"A × B (matrix multiplication):\");\n",
    "for i in 0..multiplication_result.nrows() {\n",
    "    for j in 0..multiplication_result.ncols() {\n",
    "        print!(\"{:6.1} \", multiplication_result.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Matrix-vector multiplication\n",
    "let test_vector = vec64![1.0, 2.0, 3.0];\n",
    "let matrix_vector_result = &matrix_a ^ &test_vector;\n",
    "println!(\"\\nA × v:\");\n",
    "println!(\"{:?}\", matrix_vector_result.to_slice());\n",
    "\n",
    "// Verify associativity: (AB)C = A(BC)\n",
    "let matrix_c_test = array64![\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [0.4, 0.5, 0.6],\n",
    "    [0.7, 0.8, 0.9]\n",
    "];\n",
    "let left_associative_result = (&matrix_a ^ &matrix_b) ^ &matrix_c_test;\n",
    "let right_associative_result = &matrix_a ^ (&matrix_b ^ &matrix_c_test);\n",
    "\n",
    "// Calculate absolute difference manually\n",
    "let associativity_difference = &left_associative_result - &right_associative_result;\n",
    "let mut total_absolute_sum = 0.0;\n",
    "for i in 0..associativity_difference.nrows() {\n",
    "    for j in 0..associativity_difference.ncols() {\n",
    "        total_absolute_sum += associativity_difference.get(i, j).unwrap().abs();\n",
    "    }\n",
    "}\n",
    "println!(\"\\nAssociativity check sum||(AB)C - A(BC)||: {:.2e}\", total_absolute_sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transpose-trace",
   "metadata": {},
   "source": [
    "## Matrix Transpose and Trace Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "transpose-trace-ops",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A × v:\n",
      "[14.0, 32.0, 50.0]\n",
      "\n",
      "Associativity check sum||(AB)C - A(BC)||: 3.55e-14\n",
      "A transpose:\n",
      "   1.0    4.0    7.0 \n",
      "   2.0    5.0    8.0 \n",
      "   3.0    6.0    9.0 \n"
     ]
    }
   ],
   "source": [
    "// Matrix transpose\n",
    "let matrix_a_transpose = matrix_a.transpose();\n",
    "println!(\"A transpose:\");\n",
    "for i in 0..matrix_a_transpose.nrows() {\n",
    "    for j in 0..matrix_a_transpose.ncols() {\n",
    "        print!(\"{:6.1} \", matrix_a_transpose.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Trace (sum of diagonal elements) - compute manually for demonstration\n",
    "let mut trace_value = 0.0;\n",
    "for i in 0..matrix_a.nrows().min(matrix_a.ncols()) {\n",
    "    trace_value += matrix_a.get(i, i).unwrap();\n",
    "}\n",
    "println!(\"\\nTrace of A: {}\", trace_value);\n",
    "\n",
    "// Verify transpose properties: (A^T)^T = A\n",
    "let double_transpose = matrix_a_transpose.transpose();\n",
    "let mut difference_sum = 0.0;\n",
    "for i in 0..matrix_a.nrows() {\n",
    "    for j in 0..matrix_a.ncols() {\n",
    "        difference_sum += (matrix_a.get(i, j).unwrap() - double_transpose.get(i, j).unwrap()).abs();\n",
    "    }\n",
    "}\n",
    "println!(\"Transpose property ||(A^T)^T - A||: {:.2e}\", difference_sum);\n",
    "\n",
    "// Symmetric matrix check\n",
    "let symmetric_matrix = &matrix_a + &matrix_a_transpose;\n",
    "let sym_transpose_check = symmetric_matrix.transpose();\n",
    "let mut sym_difference = 0.0;\n",
    "for i in 0..symmetric_matrix.nrows() {\n",
    "    for j in 0..symmetric_matrix.ncols() {\n",
    "        sym_difference += (symmetric_matrix.get(i, j).unwrap() - sym_transpose_check.get(i, j).unwrap()).abs();\n",
    "    }\n",
    "}\n",
    "println!(\"\\nSymmetric matrix check ||S - S^T||: {:.2e}\", sym_difference);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norms-determinant",
   "metadata": {},
   "source": [
    "## Matrix Norms and Determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "norms-det",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trace of A: 15\n",
      "Transpose property ||(A^T)^T - A||: 0.00e0\n",
      "\n",
      "Symmetric matrix check ||S - S^T||: 0.00e0\n",
      "Matrix norms for A:\n",
      "  Frobenius norm: 16.8819\n",
      "  Max norm:       9.0000\n",
      "\n",
      "=== ERGONOMIC DETERMINANT COMPUTATION ===\n",
      "Determinant of A (ergonomic): -0.000000\n",
      "  → Matrix A is singular (not invertible)\n",
      "Determinant of well-conditioned matrix: 43.000000\n",
      "  → Well-conditioned and invertible (det ≠ 0)\n",
      "\n",
      "2×2 Matrix determinant:\n",
      "  Ergonomic det(): 10.000000\n",
      "  Manual (ad-bc): 10.000000\n",
      "  Difference: 0.00e0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculate matrix norms manually for demonstration\n",
    "let mut frobenius_norm_value: f64 = 0.0;\n",
    "let mut maximum_element_value: f64 = 0.0;\n",
    "for i in 0..matrix_a.nrows() {\n",
    "    for j in 0..matrix_a.ncols() {\n",
    "        let element_value = matrix_a.get(i, j).unwrap();\n",
    "        frobenius_norm_value += element_value * element_value;\n",
    "        maximum_element_value = maximum_element_value.max(element_value.abs());\n",
    "    }\n",
    "}\n",
    "frobenius_norm_value = frobenius_norm_value.sqrt();\n",
    "\n",
    "println!(\"Matrix norms for A:\");\n",
    "println!(\"  Frobenius norm: {:.4}\", frobenius_norm_value);\n",
    "println!(\"  Max norm:       {:.4}\", maximum_element_value);\n",
    "\n",
    "// 🎯 Ergonomic determinant calculation using rustlab-linearalgebra\n",
    "println!(\"\\n=== ERGONOMIC DETERMINANT COMPUTATION ===\");\n",
    "match matrix_a.det() {\n",
    "    Ok(det_a) => {\n",
    "        println!(\"Determinant of A (ergonomic): {:.6}\", det_a);\n",
    "        if det_a.abs() < 1e-10 {\n",
    "            println!(\"  → Matrix A is singular (not invertible)\");\n",
    "        } else {\n",
    "            println!(\"  → Matrix A is invertible\");\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"Determinant computation failed: {}\", e);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Create a well-conditioned matrix for better determinant example\n",
    "let well_conditioned_matrix = array64![\n",
    "    [4.0, 1.0, 2.0],\n",
    "    [1.0, 3.0, 1.0],\n",
    "    [2.0, 1.0, 5.0]\n",
    "];\n",
    "\n",
    "match well_conditioned_matrix.det() {\n",
    "    Ok(det_well) => {\n",
    "        println!(\"Determinant of well-conditioned matrix: {:.6}\", det_well);\n",
    "        println!(\"  → Well-conditioned and invertible (det ≠ 0)\");\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"Well-conditioned determinant failed: {}\", e);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Compare with 2×2 matrix for verification\n",
    "let matrix_2x2 = array64![\n",
    "    [3.0, 2.0],\n",
    "    [1.0, 4.0]\n",
    "];\n",
    "\n",
    "match matrix_2x2.det() {\n",
    "    Ok(det_2x2) => {\n",
    "        let manual_det = 3.0 * 4.0 - 2.0 * 1.0; // ad - bc formula\n",
    "        println!(\"\\n2×2 Matrix determinant:\");\n",
    "        println!(\"  Ergonomic det(): {:.6}\", det_2x2);\n",
    "        println!(\"  Manual (ad-bc): {:.6}\", manual_det);\n",
    "        println!(\"  Difference: {:.2e}\", (det_2x2 - manual_det).abs());\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"2×2 determinant failed: {}\", e);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-systems",
   "metadata": {},
   "source": [
    "## Solving Linear Systems\n",
    "\n",
    "Demonstrate solving Ax = b using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "linear-solve",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving linear system Ax = b\n",
      "System matrix A:\n",
      "   3.0    1.0    1.0 \n",
      "   1.0    4.0    1.0 \n",
      "   2.0    1.0    5.0 \n",
      "Right-hand side b: [11.0, 16.0, 21.0]\n",
      "\n",
      "Expected solution should be approximately [2, 3, 1]\n",
      "Verification A * [2,3,1]: [10.0, 15.0, 12.0]\n",
      "Should match b: [11.0, 16.0, 21.0]\n",
      "Residual sum: 1.10e1\n"
     ]
    }
   ],
   "source": [
    "// Create a well-conditioned system Ax = b\n",
    "let a_sys = array64![\n",
    "    [3.0, 1.0, 1.0],\n",
    "    [1.0, 4.0, 1.0],\n",
    "    [2.0, 1.0, 5.0]\n",
    "];\n",
    "\n",
    "let b_vec = vec64![11.0, 16.0, 21.0];\n",
    "\n",
    "println!(\"Solving linear system Ax = b\");\n",
    "println!(\"System matrix A:\");\n",
    "for i in 0..a_sys.nrows() {\n",
    "    for j in 0..a_sys.ncols() {\n",
    "        print!(\"{:6.1} \", a_sys.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "println!(\"Right-hand side b: {:?}\", b_vec.to_slice());\n",
    "\n",
    "// For demonstration, let's solve using manual Gaussian elimination for a simple 3x3\n",
    "// This is educational - in practice use optimized library functions\n",
    "println!(\"\\nExpected solution should be approximately [2, 3, 1]\");\n",
    "\n",
    "// Verify with a known solution\n",
    "let expected = vec64![2.0, 3.0, 1.0];\n",
    "let verification = &a_sys ^ &expected;\n",
    "println!(\"Verification A * [2,3,1]: {:?}\", verification.to_slice());\n",
    "println!(\"Should match b: {:?}\", b_vec.to_slice());\n",
    "\n",
    "let mut residual_sum = 0.0;\n",
    "for i in 0..verification.len() {\n",
    "    residual_sum += (verification.get(i).unwrap() - b_vec.get(i).unwrap()).abs();\n",
    "}\n",
    "println!(\"Residual sum: {:.2e}\", residual_sum);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decompositions",
   "metadata": {},
   "source": [
    "## Matrix Decompositions\n",
    "\n",
    "Explore various matrix decompositions available in RustLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qr-decomposition",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR Decomposition:\n",
      "Matrix for QR (3x3):\n",
      "   1.0    2.0    3.0 \n",
      "   4.0    5.0    6.0 \n",
      "   7.0    8.0   10.0 \n",
      "✅ QR decomposition successful!\n",
      "Can be used for solving linear systems.\n",
      "QR solution to test system (3x1):\n",
      "  1.0000 \n",
      "  1.0000 \n",
      "  1.0000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// QR Decomposition - using correct method name\n",
    "let matrix_for_qr = array64![\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],  \n",
    "    [7.0, 8.0, 10.0]  // Changed to make it full rank\n",
    "];\n",
    "\n",
    "println!(\"QR Decomposition:\");\n",
    "println!(\"Matrix for QR ({}x{}):\", matrix_for_qr.nrows(), matrix_for_qr.ncols());\n",
    "for i in 0..matrix_for_qr.nrows() {\n",
    "    for j in 0..matrix_for_qr.ncols() {\n",
    "        print!(\"{:6.1} \", matrix_for_qr.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Use correct method name: qr() instead of qr_decomposition()\n",
    "match matrix_for_qr.qr() {\n",
    "    Ok(qr_result) => {\n",
    "        println!(\"✅ QR decomposition successful!\");\n",
    "        println!(\"Can be used for solving linear systems.\");\n",
    "        \n",
    "        // Test solving a system with this QR decomposition\n",
    "        let test_b = array64![[6.0], [15.0], [25.0]];  // Column vector as 3x1 array\n",
    "        match qr_result.solve(&test_b) {\n",
    "            Ok(solution) => {\n",
    "                println!(\"QR solution to test system ({}x{}):\", solution.nrows(), solution.ncols());\n",
    "                for i in 0..solution.nrows() {\n",
    "                    for j in 0..solution.ncols() {\n",
    "                        print!(\"{:8.4} \", solution.get(i, j).unwrap());\n",
    "                    }\n",
    "                    println!();\n",
    "                }\n",
    "            }\n",
    "            Err(e) => {\n",
    "                println!(\"QR solve failed: {}\", e);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"QR decomposition failed: {}\", e);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "svd-decomposition",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular Value Decomposition:\n",
      "U matrix (3x3):\n",
      "  0.2298  -0.8835   0.4082 \n",
      "  0.5247  -0.2408  -0.8165 \n",
      "  0.8196   0.4019   0.4082 \n",
      "\n",
      "Singular values:\n",
      "  σ_1: 9.5255\n"
     ]
    }
   ],
   "source": [
    "// Singular Value Decomposition (SVD)  \n",
    "let matrix_for_svd = array64![\n",
    "    [1.0, 2.0],\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "];\n",
    "\n",
    "let svd_result = matrix_for_svd.svd().expect(\"SVD failed\");\n",
    "\n",
    "// Get the components using correct method names\n",
    "let u_matrix = svd_result.u();\n",
    "let singular_vals = svd_result.singular_values();\n",
    "let vt_matrix = svd_result.vt();\n",
    "\n",
    "println!(\"Singular Value Decomposition:\");\n",
    "println!(\"U matrix ({}x{}):\", u_matrix.nrows(), u_matrix.ncols());\n",
    "for i in 0..u_matrix.nrows() {\n",
    "    for j in 0..u_matrix.ncols() {\n",
    "        print!(\"{:8.4} \", u_matrix.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "println!(\"\\nSingular values:\");\n",
    "for (i, &val) in singular_vals.iter().enumerate() {\n",
    "    println!(\"  σ_{}: {:.4}\", i + 1, val);\n",
    "}\n",
    "\n",
    "println!(\"\\nV^T matrix ({}x{}):\", vt_matrix.nrows(), vt_matrix.ncols());\n",
    "for i in 0..vt_matrix.nrows() {\n",
    "    for j in 0..vt_matrix.ncols() {\n",
    "        print!(\"{:8.4} \", vt_matrix.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Create diagonal matrix from singular values manually\n",
    "let mut diagonal_s = ArrayF64::zeros(u_matrix.ncols(), vt_matrix.nrows());\n",
    "for (i, &val) in singular_vals.iter().enumerate() {\n",
    "    // Set diagonal element (only set if within matrix bounds)\n",
    "    if i < diagonal_s.nrows() && i < diagonal_s.ncols() {\n",
    "        // Since we can't directly set elements, we'll skip full reconstruction\n",
    "        // and just verify the decomposition properties instead\n",
    "    }\n",
    "}\n",
    "\n",
    "println!(\"\\nSVD Properties:\");\n",
    "println!(\"  Original matrix: {}x{}\", matrix_for_svd.nrows(), matrix_for_svd.ncols());\n",
    "println!(\"  U matrix: {}x{}\", u_matrix.nrows(), u_matrix.ncols());\n",
    "println!(\"  Number of singular values: {}\", singular_vals.len());\n",
    "println!(\"  V^T matrix: {}x{}\", vt_matrix.nrows(), vt_matrix.ncols());\n",
    "\n",
    "// Verify the singular values are in descending order\n",
    "let mut is_sorted = true;\n",
    "for i in 1..singular_vals.len() {\n",
    "    if singular_vals[i] > singular_vals[i-1] {\n",
    "        is_sorted = false;\n",
    "        break;\n",
    "    }\n",
    "}\n",
    "println!(\"  Singular values sorted (desc): {}\", is_sorted);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cholesky-decomposition",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  σ_2: 0.5143\n",
      "\n",
      "V^T matrix (2x2):\n",
      "  0.6196   0.7849 \n",
      "  0.7849  -0.6196 \n",
      "\n",
      "SVD Properties:\n",
      "  Original matrix: 3x2\n",
      "  U matrix: 3x3\n",
      "  Number of singular values: 2\n",
      "  V^T matrix: 2x2\n",
      "  Singular values sorted (desc): true\n",
      "Testing positive definite matrix for Cholesky:\n",
      "   4.0    2.0    1.0 \n",
      "   2.0    3.0    0.5 \n",
      "   1.0    0.5    2.0 \n",
      "✅ Cholesky decomposition successful!\n",
      "Cholesky solution (3x1):\n",
      "  0.6786 \n",
      "  1.5000 \n",
      "  2.2857 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Cholesky Decomposition (for positive definite matrices)\n",
    "let pos_def = array64![\n",
    "    [4.0, 2.0, 1.0],\n",
    "    [2.0, 3.0, 0.5],\n",
    "    [1.0, 0.5, 2.0]\n",
    "];\n",
    "\n",
    "println!(\"Testing positive definite matrix for Cholesky:\");\n",
    "for i in 0..pos_def.nrows() {\n",
    "    for j in 0..pos_def.ncols() {\n",
    "        print!(\"{:6.1} \", pos_def.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Use the cholesky() method from linearalgebra\n",
    "match pos_def.cholesky() {\n",
    "    Ok(chol_result) => {\n",
    "        println!(\"✅ Cholesky decomposition successful!\");\n",
    "        \n",
    "        // Test solving with Cholesky\n",
    "        let test_rhs = array64![[8.0], [7.0], [6.0]];\n",
    "        match chol_result.solve(&test_rhs) {\n",
    "            Ok(chol_solution) => {\n",
    "                println!(\"Cholesky solution ({}x{}):\", chol_solution.nrows(), chol_solution.ncols());\n",
    "                for i in 0..chol_solution.nrows() {\n",
    "                    for j in 0..chol_solution.ncols() {\n",
    "                        print!(\"{:8.4} \", chol_solution.get(i, j).unwrap());\n",
    "                    }\n",
    "                    println!();\n",
    "                }\n",
    "            }\n",
    "            Err(e) => {\n",
    "                println!(\"❌ Cholesky solve failed: {}\", e);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"❌ Cholesky decomposition failed: {}\", e);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matrix-powers",
   "metadata": {},
   "source": [
    "## Matrix Powers and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "matrix-powers-funcs",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base matrix A:\n",
      "   2.0    1.0 \n",
      "   1.0    2.0 \n",
      "\n",
      "Determinant: 3.000000\n",
      "  ✅ Matrix is invertible (det ≠ 0)\n",
      "\n",
      "🎯 Ergonomic A⁻¹ (via rustlab-linearalgebra):\n",
      "  0.6667  -0.3333 \n",
      " -0.3333   0.6667 \n",
      "\n",
      "Verification A*A⁻¹:\n",
      "  1.0000   0.0000 \n",
      "  0.0000   1.0000 \n",
      "\n",
      "Condition number estimate: 1.00e0\n",
      "\n",
      "A²:\n",
      "   5.0    4.0 \n",
      "   4.0    5.0 \n",
      "\n",
      "A³:\n",
      "  14.0   13.0 \n",
      "  13.0   14.0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Matrix powers\n",
    "let base_matrix = array64![\n",
    "    [2.0, 1.0],\n",
    "    [1.0, 2.0]\n",
    "];\n",
    "\n",
    "println!(\"Base matrix A:\");\n",
    "for i in 0..base_matrix.nrows() {\n",
    "    for j in 0..base_matrix.ncols() {\n",
    "        print!(\"{:6.1} \", base_matrix.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Check determinant before computing inverse (best practice)\n",
    "match base_matrix.det() {\n",
    "    Ok(det_val) => {\n",
    "        println!(\"\\nDeterminant: {:.6}\", det_val);\n",
    "        if det_val.abs() > 1e-10 {\n",
    "            println!(\"  ✅ Matrix is invertible (det ≠ 0)\");\n",
    "            \n",
    "            // Safe to compute inverse using rustlab-linearalgebra\n",
    "            match base_matrix.inv() {\n",
    "                Ok(a_inverse) => {\n",
    "                    println!(\"\\n🎯 Ergonomic A⁻¹ (via rustlab-linearalgebra):\");\n",
    "                    for i in 0..a_inverse.nrows() {\n",
    "                        for j in 0..a_inverse.ncols() {\n",
    "                            print!(\"{:8.4} \", a_inverse.get(i, j).unwrap());\n",
    "                        }\n",
    "                        println!();\n",
    "                    }\n",
    "                    \n",
    "                    // Verify A * A^(-1) = I\n",
    "                    let identity_check = &base_matrix ^ &a_inverse;\n",
    "                    println!(\"\\nVerification A*A⁻¹:\");\n",
    "                    for i in 0..identity_check.nrows() {\n",
    "                        for j in 0..identity_check.ncols() {\n",
    "                            print!(\"{:8.4} \", identity_check.get(i, j).unwrap());\n",
    "                        }\n",
    "                        println!();\n",
    "                    }\n",
    "                    \n",
    "                    // Calculate condition number using determinants\n",
    "                    let inv_det = a_inverse.det().unwrap_or(0.0);\n",
    "                    let condition_estimate = 1.0 / (det_val.abs() * inv_det.abs());\n",
    "                    println!(\"\\nCondition number estimate: {:.2e}\", condition_estimate);\n",
    "                }\n",
    "                Err(e) => {\n",
    "                    println!(\"❌ Inverse computation failed: {}\", e);\n",
    "                }\n",
    "            }\n",
    "        } else {\n",
    "            println!(\"  ❌ Matrix is singular (det ≈ 0) - cannot invert\");\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"❌ Determinant computation failed: {}\", e);\n",
    "    }\n",
    "}\n",
    "\n",
    "// A^2 = A * A\n",
    "let a_squared = &base_matrix ^ &base_matrix;\n",
    "println!(\"\\nA²:\");\n",
    "for i in 0..a_squared.nrows() {\n",
    "    for j in 0..a_squared.ncols() {\n",
    "        print!(\"{:6.1} \", a_squared.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// A^3 = A^2 * A  \n",
    "let a_cubed = &a_squared ^ &base_matrix;\n",
    "println!(\"\\nA³:\");\n",
    "for i in 0..a_cubed.nrows() {\n",
    "    for j in 0..a_cubed.ncols() {\n",
    "        print!(\"{:6.1} \", a_cubed.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-operations",
   "metadata": {},
   "source": [
    "## Advanced Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "advanced-ops",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test matrix for advanced properties:\n",
      "   1.0    2.0    3.0 \n",
      "   4.0    5.0    6.0 \n",
      "   7.0    8.0    9.1 \n",
      "\n",
      "Matrix rank: 3\n",
      "Condition number: 9.95e2\n",
      "Matrix is well-conditioned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Advanced Matrix Properties\n",
    "let test_matrix = array64![\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.1]  // Slightly perturbed to avoid singularity\n",
    "];\n",
    "\n",
    "println!(\"Test matrix for advanced properties:\");\n",
    "for i in 0..test_matrix.nrows() {\n",
    "    for j in 0..test_matrix.ncols() {\n",
    "        print!(\"{:6.1} \", test_matrix.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Calculate rank and condition number using SVD\n",
    "match test_matrix.svd() {\n",
    "    Ok(svd_for_rank) => {\n",
    "        let singular_vals = svd_for_rank.singular_values();\n",
    "        let tolerance = 1e-10;\n",
    "        let rank = singular_vals.iter().filter(|&&val| val > tolerance).count();\n",
    "        println!(\"\\nMatrix rank: {}\", rank);\n",
    "        \n",
    "        // Condition number (ratio of largest to smallest non-zero singular value)\n",
    "        if let (Some(&max_sv), Some(&min_sv)) = (singular_vals.first(), singular_vals.last()) {\n",
    "            if min_sv > tolerance {\n",
    "                let condition_number = max_sv / min_sv;\n",
    "                println!(\"Condition number: {:.2e}\", condition_number);\n",
    "                \n",
    "                if condition_number > 1e12 {\n",
    "                    println!(\"Warning: Matrix is ill-conditioned!\");\n",
    "                } else if condition_number > 1e6 {\n",
    "                    println!(\"Caution: Matrix is moderately ill-conditioned\");\n",
    "                } else {\n",
    "                    println!(\"Matrix is well-conditioned\");\n",
    "                }\n",
    "            } else {\n",
    "                println!(\"Matrix is singular (condition number = ∞)\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"❌ SVD for rank/condition failed: {}\", e);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "omrijnkkk7n",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors\n",
    "\n",
    "Compute eigenvalues and eigenvectors for square matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "p7bvd4ivbyb",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues (real, nondecreasing order):\n",
      "  λ_1: 2.307979\n",
      "  λ_2: 2.643104\n",
      "  λ_3: 7.048917\n",
      "\n",
      "Matrix properties:\n",
      "  Trace: 12.0000\n",
      "  Sum of eigenvalues: 12.0000\n",
      "  Product of eigenvalues: 43.0000\n",
      "\n",
      "Verification:\n",
      "  |trace - Σλᵢ|: 0.00e0\n",
      "\n",
      "Computing general eigenvalues (may be complex):\n",
      "  λ_1: 7.048917\n",
      "  λ_2: 2.307979\n",
      "  λ_3: 2.643104\n",
      "\n",
      "=== Eigenvector Computation ===\n",
      "Eigenvectors computed successfully!\n",
      "Matrix has 3 eigenvalue-eigenvector pairs\n",
      "Eigenvector matrix dimensions: 3x3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a symmetric matrix for real eigenvalues\n",
    "let symmetric_matrix = array64![\n",
    "    [4.0, 1.0, 2.0],\n",
    "    [1.0, 3.0, 1.0],\n",
    "    [2.0, 1.0, 5.0]\n",
    "];\n",
    "\n",
    "// Compute eigenvalues for symmetric (self-adjoint) matrix - returns real values\n",
    "match symmetric_matrix.eigenvalues_self_adjoint() {\n",
    "    Ok(eigenvals) => {\n",
    "        println!(\"Eigenvalues (real, nondecreasing order):\");\n",
    "        for (i, &val) in eigenvals.iter().enumerate() {\n",
    "            println!(\"  λ_{}: {:.6}\", i + 1, val);\n",
    "        }\n",
    "        \n",
    "        // For symmetric matrices, eigenvalues are always real\n",
    "        println!(\"\\nMatrix properties:\");\n",
    "        \n",
    "        // Calculate trace manually\n",
    "        let mut trace = 0.0;\n",
    "        for i in 0..symmetric_matrix.nrows().min(symmetric_matrix.ncols()) {\n",
    "            trace += symmetric_matrix.get(i, i).unwrap();\n",
    "        }\n",
    "        println!(\"  Trace: {:.4}\", trace);\n",
    "        \n",
    "        // Sum of eigenvalues\n",
    "        let eigenval_sum: f64 = eigenvals.iter().sum();\n",
    "        println!(\"  Sum of eigenvalues: {:.4}\", eigenval_sum);\n",
    "        \n",
    "        // Product of eigenvalues  \n",
    "        let eigenval_product: f64 = eigenvals.iter().product();\n",
    "        println!(\"  Product of eigenvalues: {:.4}\", eigenval_product);\n",
    "        \n",
    "        // The trace should equal the sum of eigenvalues\n",
    "        let trace_error = (trace - eigenval_sum).abs();\n",
    "        println!(\"\\nVerification:\");\n",
    "        println!(\"  |trace - Σλᵢ|: {:.2e}\", trace_error);\n",
    "        \n",
    "        // For general matrices, we can also compute complex eigenvalues\n",
    "        println!(\"\\nComputing general eigenvalues (may be complex):\");\n",
    "        match symmetric_matrix.eigenvalues() {\n",
    "            Ok(complex_eigenvals) => {\n",
    "                for (i, eigenval) in complex_eigenvals.iter().enumerate() {\n",
    "                    if eigenval.im.abs() < 1e-10 {\n",
    "                        println!(\"  λ_{}: {:.6}\", i + 1, eigenval.re);\n",
    "                    } else {\n",
    "                        println!(\"  λ_{}: {:.6} + {:.6}i\", i + 1, eigenval.re, eigenval.im);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            Err(e) => {\n",
    "                println!(\"  Complex eigenvalue computation failed: {}\", e);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"Eigenvalue computation failed: {}\", e);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Test eigenvectors for the symmetric matrix\n",
    "println!(\"\\n=== Eigenvector Computation ===\");\n",
    "match symmetric_matrix.eigenvectors_self_adjoint() {\n",
    "    Ok((eigenvals, eigenvecs)) => {\n",
    "        println!(\"Eigenvectors computed successfully!\");\n",
    "        println!(\"Matrix has {} eigenvalue-eigenvector pairs\", eigenvals.len());\n",
    "        \n",
    "        // The eigenvectors form an orthonormal basis\n",
    "        println!(\"Eigenvector matrix dimensions: {}x{}\", eigenvecs.nrows(), eigenvecs.ncols());\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"Eigenvector computation failed: {}\", e);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance-comparison",
   "metadata": {},
   "source": [
    "## Performance Considerations\n",
    "\n",
    "Understanding the computational complexity of different operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "performance-demo",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance comparison for 100x100 matrices:\n",
      "\n",
      "Matrix multiplication: 6.29ms\n",
      "Matrix addition: 83.47µs\n",
      "Matrix transpose: 68.07µs\n",
      "\n",
      "Complexity comparison:\n",
      "  Multiplication vs Addition: 75.4x slower\n",
      "\n",
      "Complexity notes:\n",
      "  Matrix multiply: O(n³) - most expensive operation\n",
      "  Addition: O(n²) - linear in matrix size\n"
     ]
    }
   ],
   "source": [
    "// Performance comparison for different operations\n",
    "use std::time::Instant;\n",
    "\n",
    "// Create smaller matrices for timing (to keep demo fast)\n",
    "let size = 100;\n",
    "\n",
    "// Create test matrices with explicit type annotations\n",
    "let perf_a: ArrayF64 = eye(size); // Identity matrix\n",
    "let perf_b: ArrayF64 = eye(size);\n",
    "\n",
    "println!(\"Performance comparison for {}x{} matrices:\", size, size);\n",
    "\n",
    "// Matrix multiplication timing\n",
    "let start = Instant::now();\n",
    "let _product = &perf_a ^ &perf_b;\n",
    "let mult_time = start.elapsed();\n",
    "println!(\"\\nMatrix multiplication: {:.2?}\", mult_time);\n",
    "\n",
    "// Matrix addition timing\n",
    "let start = Instant::now();\n",
    "let _sum = &perf_a + &perf_b;\n",
    "let add_time = start.elapsed();\n",
    "println!(\"Matrix addition: {:.2?}\", add_time);\n",
    "\n",
    "// Transpose timing\n",
    "let start = Instant::now();\n",
    "let _transpose = perf_a.transpose();\n",
    "let trans_time = start.elapsed();\n",
    "println!(\"Matrix transpose: {:.2?}\", trans_time);\n",
    "\n",
    "if add_time.as_nanos() > 0 {\n",
    "    println!(\"\\nComplexity comparison:\");\n",
    "    println!(\"  Multiplication vs Addition: {:.1}x slower\", \n",
    "            mult_time.as_nanos() as f64 / add_time.as_nanos() as f64);\n",
    "}\n",
    "\n",
    "println!(\"\\nComplexity notes:\");\n",
    "println!(\"  Matrix multiply: O(n³) - most expensive operation\");\n",
    "println!(\"  Addition: O(n²) - linear in matrix size\");\n",
    "println!(\"  Transpose: O(1) - just metadata, no data movement\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-example",
   "metadata": {},
   "source": [
    "## Practical Example: Least Squares Regression\n",
    "\n",
    "Solve the normal equations using matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "least-squares-demo",
   "metadata": {
    "vscode": {
     "languageId": "rust"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transpose: O(1) - just metadata, no data movement\n",
      "Least squares regression example:\n",
      "Samples: 10, Features: 1 (+ intercept)\n",
      "True coefficients: [1.0, 2.0]\n",
      "\n",
      "X'X matrix:\n",
      "    10.0     55.0 \n",
      "    55.0    385.0 \n",
      "\n",
      "LU solution:\n",
      "  1.0367   1.9942 \n",
      "Sum of squared errors: 0.109515\n",
      "Coefficient error ||β_estimated - β_true||: 0.037116\n",
      "\n",
      "Using QR decomposition of X'X:\n",
      "QR solution via normal equations:\n",
      "  1.0367   1.9942 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Simple 2D linear regression example  \n",
    "let n_samples = 10;\n",
    "\n",
    "// Create design matrix X with intercept column\n",
    "let x_data = array64![\n",
    "    [1.0, 1.0],\n",
    "    [1.0, 2.0],\n",
    "    [1.0, 3.0],\n",
    "    [1.0, 4.0],\n",
    "    [1.0, 5.0],\n",
    "    [1.0, 6.0],\n",
    "    [1.0, 7.0],\n",
    "    [1.0, 8.0],\n",
    "    [1.0, 9.0],\n",
    "    [1.0, 10.0]\n",
    "];\n",
    "\n",
    "// True coefficients: [intercept=1.0, slope=2.0]\n",
    "let true_coef = vec64![1.0, 2.0];\n",
    "\n",
    "// Generate target: y = 1.0 + 2.0*x + noise\n",
    "let y_clean = &x_data ^ &true_coef;\n",
    "\n",
    "// Add small amount of noise manually\n",
    "let noise_values = vec64![0.1, -0.1, 0.05, -0.05, 0.2, -0.15, 0.1, -0.1, 0.05, -0.05];\n",
    "let y_noisy = &y_clean + &noise_values;\n",
    "\n",
    "println!(\"Least squares regression example:\");\n",
    "println!(\"Samples: {}, Features: 1 (+ intercept)\", n_samples);\n",
    "println!(\"True coefficients: {:?}\", true_coef.to_slice());\n",
    "\n",
    "// Solve normal equations: β = (X'X)⁻¹X'y\n",
    "let xt_x = &x_data.transpose() ^ &x_data;\n",
    "let xty = &x_data.transpose() ^ &y_noisy;\n",
    "\n",
    "println!(\"\\nX'X matrix:\");\n",
    "for i in 0..xt_x.nrows() {\n",
    "    for j in 0..xt_x.ncols() {\n",
    "        print!(\"{:8.1} \", xt_x.get(i, j).unwrap());\n",
    "    }\n",
    "    println!();\n",
    "}\n",
    "\n",
    "// Solve using LU decomposition\n",
    "match xt_x.lu() {\n",
    "    Ok(lu_solver) => {\n",
    "        // Convert vector to 2x1 column array\n",
    "        let xty_col = array64![[xty.get(0).unwrap()], [xty.get(1).unwrap()]];\n",
    "        match lu_solver.solve(&xty_col) {\n",
    "            Ok(beta_solution) => {\n",
    "                println!(\"\\nLU solution:\");\n",
    "                for i in 0..beta_solution.nrows() {\n",
    "                    print!(\"{:8.4} \", beta_solution.get(i, 0).unwrap());\n",
    "                }\n",
    "                println!();\n",
    "                \n",
    "                // Calculate residuals\n",
    "                let beta_vec = vec64![beta_solution.get(0, 0).unwrap(), beta_solution.get(1, 0).unwrap()];\n",
    "                let y_pred = &x_data ^ &beta_vec;\n",
    "                let residuals = &y_noisy - &y_pred;\n",
    "                \n",
    "                let mut sse = 0.0;\n",
    "                for i in 0..residuals.len() {\n",
    "                    let resid = residuals.get(i).unwrap();\n",
    "                    sse += resid * resid;\n",
    "                }\n",
    "                \n",
    "                println!(\"Sum of squared errors: {:.6}\", sse);\n",
    "                \n",
    "                // Calculate coefficient error\n",
    "                let coef_error = (&beta_vec - &true_coef).norm();\n",
    "                println!(\"Coefficient error ||β_estimated - β_true||: {:.6}\", coef_error);\n",
    "            }\n",
    "            Err(e) => {\n",
    "                println!(\"❌ LU solve for regression failed: {}\", e);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"❌ LU decomposition for regression failed: {}\", e);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Using QR via normal equations for comparison\n",
    "println!(\"\\nUsing QR decomposition of X'X:\");\n",
    "match xt_x.qr() {\n",
    "    Ok(qr_solver) => {\n",
    "        let xty_col_qr = array64![[xty.get(0).unwrap()], [xty.get(1).unwrap()]];\n",
    "        match qr_solver.solve(&xty_col_qr) {\n",
    "            Ok(beta_qr) => {\n",
    "                println!(\"QR solution via normal equations:\");\n",
    "                for i in 0..beta_qr.nrows() {\n",
    "                    print!(\"{:8.4} \", beta_qr.get(i, 0).unwrap());\n",
    "                }\n",
    "                println!();\n",
    "            }\n",
    "            Err(e) => {\n",
    "                println!(\"❌ QR solve for regression failed: {}\", e);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Err(e) => {\n",
    "        println!(\"❌ QR decomposition for regression failed: {}\", e);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered essential matrix operations and linear algebra concepts:\n",
    "\n",
    "### Key Operations Learned:\n",
    "- **Matrix Creation**: `array64![]`, `eye()`, `zeros()`\n",
    "- **Arithmetic**: `+`, `-`, `*` (scalar), `^` (matrix multiply), element-wise `*`\n",
    "- **Properties**: `transpose()`, trace calculation, norms\n",
    "- **🎯 Ergonomic Linear Algebra**: `det()`, `inv()` from rustlab-linearalgebra\n",
    "- **Decompositions**: \n",
    "  - `qr()` - QR decomposition\n",
    "  - `svd()` - Singular Value Decomposition  \n",
    "  - `cholesky()` - Cholesky decomposition\n",
    "  - `lu()` - LU decomposition\n",
    "  - `eigenvalues()`, `eigenvalues_self_adjoint()` - Eigenvalue computation\n",
    "  - `eigenvectors()`, `eigenvectors_self_adjoint()` - Eigenvector computation\n",
    "- **Solving Systems**: `solve()` method on decomposition results\n",
    "\n",
    "### 🚀 Ergonomic Best Practices:\n",
    "1. **Check invertibility**: Use `matrix.det()?` before `matrix.inv()`\n",
    "2. **Error handling**: Both methods return `Result<T>` for safety\n",
    "3. **Mathematical notation**: `A.det()` and `A.inv()` mirror textbook notation\n",
    "4. **Performance**: O(n³) complexity using optimized LU decomposition\n",
    "\n",
    "### Performance Guidelines:\n",
    "- Matrix multiplication: O(n³) - most expensive\n",
    "- Matrix addition: O(n²) - efficient\n",
    "- Transpose: O(1) - just metadata change\n",
    "- **Determinant**: O(n³) - same cost as LU decomposition\n",
    "- **Matrix inverse**: O(n³) - use sparingly, prefer solving Ax=b directly\n",
    "\n",
    "### Numerical Considerations:\n",
    "- QR decomposition: Stable for solving overdetermined systems\n",
    "- SVD: Best for rank computation and condition number\n",
    "- Cholesky: Fast for positive definite matrices\n",
    "- LU: General purpose solver for square systems\n",
    "- **Determinant**: Use for invertibility testing, not for solving systems\n",
    "- Eigenvalues: Use `eigenvalues_self_adjoint()` for symmetric matrices (real eigenvalues)\n",
    "\n",
    "### Practical Applications:\n",
    "- Least squares regression via normal equations\n",
    "- Matrix rank and condition number via SVD\n",
    "- **Invertibility checking** with `det()` before expensive operations\n",
    "- Multiple solution methods for comparison\n",
    "\n",
    "### 🎯 Key Ergonomic Improvements:\n",
    "- **Before**: Manual 3×3 determinant calculation (error-prone)\n",
    "- **After**: `matrix.det()?` - one line, mathematically clear\n",
    "- **Before**: Complex LU-based inverse computation\n",
    "- **After**: `matrix.inv()?` - direct, safe, ergonomic\n",
    "\n",
    "**Next**: Broadcasting and advanced array operations →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
